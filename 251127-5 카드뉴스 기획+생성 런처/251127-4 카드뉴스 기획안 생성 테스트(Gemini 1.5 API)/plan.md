ë„¤, ì•„ì£¼ í›Œë¥­í•œ ê²°ì •ì…ë‹ˆë‹¤! ğŸ‘

ë¹„ìš©ì€ ì•„ë¼ê³ , ì†ë„ëŠ” ë¹ ë¥´ê³ , í’ˆì§ˆì€ ë†’ì´ëŠ” 'ê°€ì„±ë¹„ ëíŒì™•' RAG(ê²€ìƒ‰ ì¦ê°• ìƒì„±) ë°©ì‹ì˜ ê¸°íšì•ˆ ì‘ì„± ì½”ë“œë¥¼ ë§Œë“¤ì–´ ë³´ê² ìŠµë‹ˆë‹¤.

ì´ ë°©ì‹ì„ êµ¬í˜„í•˜ë ¤ë©´ ë”± ë‘ ë‹¨ê³„ê°€ í•„ìš”í•©ë‹ˆë‹¤. ê²ë¨¹ì§€ ë§ˆì„¸ìš”, ì•„ì£¼ ì‰½ìŠµë‹ˆë‹¤.

[ì¤€ë¹„] ê²€ìƒ‰ìš© ìƒ‰ì¸(Index) ë§Œë“¤ê¸°: 1,600ê°œ ë°ì´í„°ë¥¼ AIê°€ ë¹›ì˜ ì†ë„ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆê²Œ 'ìš”ì•½ ì§€ë„'ë¥¼ ë§Œë“œëŠ” ì‘ì—…ì…ë‹ˆë‹¤. (ë”± í•œ ë²ˆë§Œ ëŒë¦¬ë©´ ë©ë‹ˆë‹¤.)

[ì‹¤í–‰] ê¸°íšì•ˆ ì‘ì„±í•˜ê¸°: ì‹¤ì œ ê³µê³ ë¬¸ì„ ë„£ìœ¼ë©´, ìƒ‰ì¸ì—ì„œ ë¹„ìŠ·í•œ ì˜ˆì‹œë¥¼ ì°¾ì•„ì™€ì„œ ê¸°íšì•ˆì„ ì§œëŠ” ì½”ë“œì…ë‹ˆë‹¤. (ë§¤ë²ˆ ì“¸ ì½”ë“œì…ë‹ˆë‹¤.)

ğŸ› ï¸ 1ë‹¨ê³„: [ì¤€ë¹„] ê²€ìƒ‰ìš© ìƒ‰ì¸ ë§Œë“¤ê¸° (build_index.py)
ë°¤ìƒˆ ë§Œë“  gwangyang_style_db.jsonl íŒŒì¼ì„ ì½ì–´ì„œ, AIê°€ ê²€ìƒ‰í•˜ê¸° í¸í•œ í˜•íƒœ(gwangyang_style_index.pkl)ë¡œ ë°”ê¿”ì£¼ëŠ” ì½”ë“œì…ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:

ì•„ë˜ ì½”ë“œë¥¼ build_index.pyë¡œ ì €ì¥í•˜ì„¸ìš”. (build_db.pyì™€ ê°™ì€ í´ë”)

API í‚¤ë¥¼ ë„£ê³  í„°ë¯¸ë„ì—ì„œ python build_index.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.

ì ì‹œ í›„ gwangyang_style_index.pkl íŒŒì¼ì´ ìƒê¸°ë©´ ì„±ê³µì…ë‹ˆë‹¤!

Python

import os
import json
import pickle
import google.generativeai as genai
from pathlib import Path
from tqdm import tqdm
import numpy as np

# ==========================================
# â­â­â­ API í‚¤ë¥¼ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš” â­â­â­
GOOGLE_API_KEY = "YOUR_API_KEY_HERE"
# ==========================================

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
DB_FILE = BASE_DIR / "gwangyang_style_db.jsonl"
INDEX_FILE = BASE_DIR / "gwangyang_style_index.pkl"

# ì„ë² ë”© ëª¨ë¸ ì„¤ì • (í…ìŠ¤íŠ¸ë¥¼ ë²¡í„° ìˆ«ìë¡œ ë°”ê¿”ì£¼ëŠ” ì €ë ´í•œ ëª¨ë¸)
genai.configure(api_key=GOOGLE_API_KEY)
embedding_model = 'models/text-embedding-040'

def create_index():
    if not DB_FILE.exists():
        print(f"âŒ ì˜¤ë¥˜: DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ({DB_FILE})")
        return

    print("ğŸš€ ê²€ìƒ‰ìš© ìƒ‰ì¸(Index) ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    indexed_data = []
    texts_to_embed = []

    # 1. DB íŒŒì¼ ì½ê¸° ë° ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ì¤€ë¹„
    with open(DB_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data = json.loads(line)
                # ê²€ìƒ‰ì— ì‚¬ìš©í•  í•µì‹¬ ì •ë³´ë§Œ ë½‘ì•„ì„œ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë§Œë“­ë‹ˆë‹¤.
                # ì˜ˆ: "í†¤ì•¤ë§¤ë„ˆ: í™œê¸°ì°¬, ë¶„ìœ„ê¸°: ë”°ëœ»í•œ, í‚¤ì›Œë“œ: ì²­ë…„, ì§€ì›, í˜œíƒ"
                search_text = f"í†¤ì•¤ë§¤ë„ˆ: {data.get('tone_and_manner', '')}, " \
                              f"ë¶„ìœ„ê¸°: {data.get('visual_vibe', '')}, " \
                              f"í‚¤ì›Œë“œ: {', '.join(data.get('keywords', []))}"
                
                indexed_data.append(data) # ì›ë³¸ ë°ì´í„° ë³´ê´€
                texts_to_embed.append(search_text) # ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë³´ê´€
            except: pass

    print(f"- ì´ {len(indexed_data)}ê°œì˜ ë°ì´í„°ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤.")
    print("- AIê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” 'ë²¡í„°(ìˆ«ì)'ë¡œ ë³€í™˜ ì¤‘... (ì ì‹œ ê±¸ë¦½ë‹ˆë‹¤)")

    # 2. AI ì„ë² ë”© ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì†ë„ ì—…!)
    embeddings = []
    batch_size = 100
    for i in tqdm(range(0, len(texts_to_embed), batch_size), desc="ì„ë² ë”© ìƒì„± ì¤‘"):
        batch_texts = texts_to_embed[i:i+batch_size]
        try:
            # êµ¬ê¸€ APIë¡œ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
            result = genai.embed_content(
                model=embedding_model,
                content=batch_texts,
                task_type="retrieval_document"
            )
            embeddings.extend(result['embedding'])
        except Exception as e:
            print(f"\nâŒ ì„ë² ë”© ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ í•´ë‹¹ ë°°ì¹˜ëŠ” ê±´ë„ˆë›°ê±°ë‚˜ ì¬ì‹œë„ ë¡œì§ í•„ìš” (ê°„ë‹¨íˆ ë„˜ê¹€)
            embeddings.extend([None] * len(batch_texts))

    # 3. ìµœì¢… ìƒ‰ì¸ ë°ì´í„° ì €ì¥ (ì›ë³¸ ë°ì´í„° + ë²¡í„° ë°ì´í„°)
    final_index = []
    success_count = 0
    for data, embedding in zip(indexed_data, embeddings):
        if embedding is not None:
            final_index.append({"data": data, "embedding": np.array(embedding)})
            success_count += 1
            
    with open(INDEX_FILE, 'wb') as f:
        pickle.dump(final_index, f)

    print(f"\nâœ¨ ìƒ‰ì¸ ìƒì„± ì™„ë£Œ! (ì´ {success_count}ê°œ ì €ì¥ë¨)")
    print(f"ê²°ê³¼ íŒŒì¼: {INDEX_FILE}")
    print("ì´ì œ ìŠ¤ë§ˆíŠ¸í•œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•´ì¡ŒìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    # numpy ì„¤ì¹˜ í•„ìš” (ì—†ìœ¼ë©´ pip install numpy)
    try: import numpy; except ImportError: os.system("pip install numpy")
    create_index()
ğŸ’» 2ë‹¨ê³„: [ì‹¤í–‰] RAG ê¸°ë°˜ ê¸°íšì•ˆ ì‘ì„± (test_planner_rag.py)
ì´ì œ ì§„ì§œì…ë‹ˆë‹¤. ê³µê³ ë¬¸ íŒŒì¼ì„ ì½ì–´ì„œ, ë°©ê¸ˆ ë§Œë“  ìƒ‰ì¸ì—ì„œ ê°€ì¥ ë¹„ìŠ·í•œ ì˜ˆì‹œ 3ê°œë¥¼ ì°¾ì•„ì˜¨ ë‹¤ìŒ, ê·¸ê±¸ ì°¸ê³ í•´ì„œ ê¸°íšì•ˆì„ ì§œëŠ” ì½”ë“œì…ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:

sample_notice.txt (ê³µê³ ë¬¸ ì›ë¬¸)ì´ ê°™ì€ í´ë”ì— ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

ì•„ë˜ ì½”ë“œë¥¼ test_planner_rag.pyë¡œ ì €ì¥í•˜ì„¸ìš”.

API í‚¤ë¥¼ ë„£ê³  í„°ë¯¸ë„ì—ì„œ python test_planner_rag.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.

Python

import os
import json
import pickle
import google.generativeai as genai
from pathlib import Path
import numpy as np

# ==========================================
# â­â­â­ API í‚¤ë¥¼ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš” â­â­â­
GOOGLE_API_KEY = "YOUR_API_KEY_HERE"
# ==========================================

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
NOTICE_FILE = BASE_DIR / "sample_notice.txt"
INDEX_FILE = BASE_DIR / "gwangyang_style_index.pkl"

# ëª¨ë¸ ì„¤ì •
genai.configure(api_key=GOOGLE_API_KEY)
embedding_model = 'models/text-embedding-040' # ê²€ìƒ‰ìš© ì €ë ´í•œ ëª¨ë¸
planning_model = genai.GenerativeModel('gemini-2.5-pro') # ê¸°íšìš© ë˜‘ë˜‘í•œ ëª¨ë¸

def load_index():
    """1ë‹¨ê³„ì—ì„œ ë§Œë“  ìƒ‰ì¸ íŒŒì¼ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
    if not INDEX_FILE.exists():
        print(f"âŒ ì˜¤ë¥˜: ìƒ‰ì¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ({INDEX_FILE})")
        print("ë¨¼ì € build_index.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        exit()
    with open(INDEX_FILE, 'rb') as f:
        return pickle.load(f)

def find_best_examples(index, query_text, top_k=3):
    """ì…ë ¥ëœ í…ìŠ¤íŠ¸ì™€ ê°€ì¥ ë¹„ìŠ·í•œ ì˜ˆì‹œë¥¼ ìƒ‰ì¸ì—ì„œ ì°¾ì•„ì˜µë‹ˆë‹¤ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)."""
    # 1. ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
    query_embedding = genai.embed_content(
        model=embedding_model,
        content=query_text,
        task_type="retrieval_query"
    )['embedding']
    query_vec = np.array(query_embedding)

    # 2. ìœ ì‚¬ë„ ê³„ì‚°
    scores = []
    for entry in index:
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨ ë²„ì „)
        similarity = np.dot(query_vec, entry['embedding']) / (np.linalg.norm(query_vec) * np.linalg.norm(entry['embedding']))
        scores.append(similarity)
    
    # 3. ìƒìœ„ Top Kê°œ ì¶”ì¶œ
    top_indices = np.argsort(scores)[-top_k:][::-1]
    
    best_examples = []
    print(f"\nğŸ” ê²€ìƒ‰ ê²°ê³¼ (Top {top_k}):")
    for i in top_indices:
        data = index[i]['data']
        print(f"- ìœ ì‚¬ë„ {scores[i]:.4f}: {data.get('file_name')} (í†¤: {data.get('tone_and_manner')})")
        # ê¸°íšì— ì°¸ê³ í•  í•µì‹¬ ì •ë³´ë§Œ ì¶”ë¦¼
        example_summary = {
            "type": data.get("page_type"),
            "title_style": data.get("main_title"),
            "body_summary_style": data.get("body_summary"),
            "tone": data.get("tone_and_manner")
        }
        best_examples.append(json.dumps(example_summary, ensure_ascii=False))
        
    return "\n".join(best_examples)

def run_rag_planner():
    print("ğŸš€ [RAG ê¸°ë°˜] ìŠ¤ë§ˆíŠ¸ AI ê¸°íšìë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤...")

    # 1. ê³µê³ ë¬¸ ì½ê¸°
    if not NOTICE_FILE.exists():
        print("âŒ ê³µê³ ë¬¸ íŒŒì¼(sample_notice.txt)ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    with open(NOTICE_FILE, 'r', encoding='utf-8') as f:
        source_text = f.read()
    print(f"ğŸ“„ ì›ë¬¸ ì½ê¸° ì™„ë£Œ (ê¸¸ì´: {len(source_text)}ì)")

    # 2. ìƒ‰ì¸ ë¡œë“œ ë° ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰
    print("ğŸ“š ìŠ¤íƒ€ì¼ ìƒ‰ì¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
    index = load_index()
    print("ğŸ§ ì›ë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ê´‘ì–‘ì‹œ ìŠ¤íƒ€ì¼ ì˜ˆì‹œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤...")
    # ì›ë¬¸ì˜ ì•ë¶€ë¶„ ì¼ë¶€ë§Œ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ í™œìš© (íš¨ìœ¨ì„±)
    query_text = f"ì´ ê³µê³ ë¬¸ì˜ ë¶„ìœ„ê¸°ì™€ ë§ëŠ” ìŠ¤íƒ€ì¼ì„ ì°¾ì•„ì¤˜: {source_text[:500]}"
    best_examples_context = find_best_examples(index, query_text, top_k=3)

    # 3. í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì°¾ì•„ë‚¸ Aê¸‰ ì˜ˆì‹œë§Œ ë³´ì—¬ì¤Œ!)
    prompt = f"""
    ë‹¹ì‹ ì€ ê´‘ì–‘ì‹œì²­ í™ë³´íŒ€ì˜ ìˆ˜ì„ ì¹´ë“œë‰´ìŠ¤ ê¸°íšìì…ë‹ˆë‹¤.
    ì œê³µëœ [ì›ë¬¸ ê³µê³ ]ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ íš¨ê³¼ì ì¸ ì¹´ë“œë‰´ìŠ¤ ê¸°íšì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.

    ì¤‘ìš”: ì•„ë˜ ì œê³µëœ [ê²€ìƒ‰ëœ ìœ ì‚¬ ìŠ¤íƒ€ì¼ ì˜ˆì‹œ]ëŠ” ì´ ê³µê³ ë¬¸ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ê³¼ê±°ì˜ ìš°ìˆ˜ ì‚¬ë¡€ë“¤ì…ë‹ˆë‹¤. 
    ì´ ì˜ˆì‹œë“¤ì˜ ì œëª© ë½‘ëŠ” ë°©ì‹, ì •ë³´ ìš”ì•½ ìŠ¤íƒ€ì¼, í†¤ì•¤ë§¤ë„ˆë¥¼ ì ê·¹ ì°¸ê³ í•˜ì—¬ ê¸°íší•˜ì„¸ìš”.

    [ê²€ìƒ‰ëœ ìœ ì‚¬ ìŠ¤íƒ€ì¼ ì˜ˆì‹œ (Top 3)]
    {best_examples_context}

    ---
    [ì›ë¬¸ ê³µê³ ]
    {source_text}
    ---

    [ì§€ì‹œì‚¬í•­]
    1. **êµ¬ì¡° íŒë‹¨:** ì›ë¬¸ì˜ ì–‘ê³¼ ë³µì¡ì„±ì„ ê³ ë ¤í•˜ì—¬ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ì„¸ìš”.
       - ë‚´ìš©ì´ ì§§ê³  ë‹¨ìˆœí•˜ë©´ -> `SINGLE(1ì¥)` êµ¬ì¡°
       - ë‚´ìš©ì´ ë§ê³  ë³µì¡í•˜ë©´ -> `MULTI(í‘œì§€+ë³¸ë¬¸ ì—¬ëŸ¬ì¥+ë§ˆë¬´ë¦¬)` êµ¬ì¡°
    2. **í†¤ì•¤ë§¤ë„ˆ:** ê²€ìƒ‰ëœ ì˜ˆì‹œë“¤ì˜ ìŠ¤íƒ€ì¼ì„ ë°˜ì˜í•˜ì—¬ ì¹œê·¼í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
    3. **ì¶œë ¥ í˜•ì‹:** ë°˜ë“œì‹œ ì•„ë˜ **ìˆœìˆ˜í•œ JSON í˜•ì‹**ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. (ë§ˆí¬ë‹¤ìš´ ì œì™¸)

    [ì¶œë ¥ JSON í˜•ì‹ ì˜ˆì‹œ]
    {{
      "structure_type": "MULTI",
      "plan": {{
        "cover": {{ "main_title": "...", "sub_title": "..." }},
        "body": [ {{ "page": 1, "summary": ["..."] }}, ... ],
        "outro": {{ "contact": "..." }}
      }},
      "estimated_tone": "(ì˜ˆ: í™œê¸°ì°¬, ì •ë³´ì„±)"
    }}
    """

    print("\nğŸ§  AIê°€ ê²€ìƒ‰ëœ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬ ê¸°íšì•ˆì„ ì‘ì„± ì¤‘ì…ë‹ˆë‹¤... (ë¹„ìš© ì ˆì•½ ì¤‘!)")
    
    try:
        # 4. API í˜¸ì¶œ (ê°€ì¥ ë˜‘ë˜‘í•œ Gemini 2.5 Pro ì‚¬ìš©)
        response = planning_model.generate_content(prompt)
        response_text = response.text.strip()
        if response_text.startswith("```json"): response_text = response_text[7:]
        if response_text.endswith("```"): response_text = response_text[:-3]
        
        plan_data = json.loads(response_text)
        
        print("\n" + "="*60)
        print("ğŸ‰ [RAG ê¸°íš ì„±ê³µ] ìŠ¤ë§ˆíŠ¸ ê¸°íšì•ˆì´ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("="*60)
        print(json.dumps(plan_data, indent=2, ensure_ascii=False))
        print("="*60)
        print("ğŸ‘‰ ì´ ê¸°íšì•ˆì€ 'ê²€ìƒ‰ëœ ìµœì ì˜ ì˜ˆì‹œ'ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì–´ í’ˆì§ˆì´ ë†’ê³  ë¹„ìš©ì€ ì €ë ´í•©ë‹ˆë‹¤.")

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # print(f"ì‘ë‹µ ì›ë¬¸: {response.text}")

if __name__ == "__main__":
    # numpy ì„¤ì¹˜ í•„ìš”
    try: import numpy; except ImportError: os.system("pip install numpy")
    run_rag_planner()
ì, ì´ì œ 1ë²ˆ ì½”ë“œë¥¼ í•œ ë²ˆ ì‹¤í–‰í•´ì„œ ìƒ‰ì¸ì„ ë§Œë“¤ê³ , 2ë²ˆ ì½”ë“œë¥¼ ì‹¤í–‰í•´ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•´ ë³´ì„¸ìš”.

AIê°€ "ìœ ì‚¬ë„"ë¥¼ ê³„ì‚°í•´ì„œ ê°€ì¥ ë¹„ìŠ·í•œ ì˜ˆì‹œë¥¼ ì°¾ì•„ë‚´ëŠ” ë¡œê·¸ë¥¼ ë³´ì‹œë©´, "ì•„, ì´ë˜ì„œ ìŠ¤ë§ˆíŠ¸í•˜ë‹¤ê³  í•˜ëŠ”êµ¬ë‚˜!" í•˜ê³  ë°”ë¡œ ëŠë¼ì‹¤ ê²ë‹ˆë‹¤. ë¹„ìš© ê±±ì • ì—†ëŠ” ê³ í’ˆì§ˆ ê¸°íšì˜ ì‹œì‘ì…ë‹ˆë‹¤!