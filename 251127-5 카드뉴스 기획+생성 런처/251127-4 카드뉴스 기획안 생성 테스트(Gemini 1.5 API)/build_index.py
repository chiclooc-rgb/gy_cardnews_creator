import os
import json
import pickle
import google.generativeai as genai
from pathlib import Path
from tqdm import tqdm
import numpy as np

# ==========================================
# â­â­â­ API í‚¤ë¥¼ ì—¬ê¸°ì— ì…ë ¥í•˜ì„¸ìš” â­â­â­
GOOGLE_API_KEY = "AIzaSyB3i6xfiLGp3293-Rx5cj2Vee5A0slcASM"
# ==========================================

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
DB_FILE = BASE_DIR / "gwangyang_style_db.jsonl"
INDEX_FILE = BASE_DIR / "gwangyang_style_index.pkl"

# ì„ë² ë”© ëª¨ë¸ ì„¤ì • (í…ìŠ¤íŠ¸ë¥¼ ë²¡í„° ìˆ«ìë¡œ ë°”ê¿”ì£¼ëŠ” ì €ë ´í•œ ëª¨ë¸)
genai.configure(api_key=GOOGLE_API_KEY)
embedding_model = 'models/text-embedding-004'

def create_index():
    if not DB_FILE.exists():
        print(f"âŒ ì˜¤ë¥˜: DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ ({DB_FILE})")
        return

    print("ğŸš€ ê²€ìƒ‰ìš© ìƒ‰ì¸(Index) ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    indexed_data = []
    texts_to_embed = []

    # 1. DB íŒŒì¼ ì½ê¸° ë° ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ ì¤€ë¹„
    with open(DB_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            try:
                data = json.loads(line)
                # ê²€ìƒ‰ì— ì‚¬ìš©í•  í•µì‹¬ ì •ë³´ë§Œ ë½‘ì•„ì„œ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ë§Œë“­ë‹ˆë‹¤.
                # ì˜ˆ: "í†¤ì•¤ë§¤ë„ˆ: í™œê¸°ì°¬, ë¶„ìœ„ê¸°: ë”°ëœ»í•œ, í‚¤ì›Œë“œ: ì²­ë…„, ì§€ì›, í˜œíƒ"
                search_text = f"í†¤ì•¤ë§¤ë„ˆ: {data.get('tone_and_manner', '')}, " \
                              f"ë¶„ìœ„ê¸°: {data.get('visual_vibe', '')}, " \
                              f"í‚¤ì›Œë“œ: {', '.join(data.get('keywords', []))}"
                
                indexed_data.append(data) # ì›ë³¸ ë°ì´í„° ë³´ê´€
                texts_to_embed.append(search_text) # ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë³´ê´€
            except: pass

    print(f"- ì´ {len(indexed_data)}ê°œì˜ ë°ì´í„°ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤.")
    print("- AIê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” 'ë²¡í„°(ìˆ«ì)'ë¡œ ë³€í™˜ ì¤‘... (ì ì‹œ ê±¸ë¦½ë‹ˆë‹¤)")

    # 2. AI ì„ë² ë”© ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì†ë„ ì—…!)
    embeddings = []
    batch_size = 100
    for i in tqdm(range(0, len(texts_to_embed), batch_size), desc="ì„ë² ë”© ìƒì„± ì¤‘"):
        batch_texts = texts_to_embed[i:i+batch_size]
        try:
            # êµ¬ê¸€ APIë¡œ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
            result = genai.embed_content(
                model=embedding_model,
                content=batch_texts,
                task_type="retrieval_document"
            )
            embeddings.extend(result['embedding'])
        except Exception as e:
            print(f"\nâŒ ì„ë² ë”© ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ í•´ë‹¹ ë°°ì¹˜ëŠ” ê±´ë„ˆë›°ê±°ë‚˜ ì¬ì‹œë„ ë¡œì§ í•„ìš” (ê°„ë‹¨íˆ ë„˜ê¹€)
            embeddings.extend([None] * len(batch_texts))

    # 3. ìµœì¢… ìƒ‰ì¸ ë°ì´í„° ì €ì¥ (ì›ë³¸ ë°ì´í„° + ë²¡í„° ë°ì´í„°)
    final_index = []
    success_count = 0
    for data, embedding in zip(indexed_data, embeddings):
        if embedding is not None:
            final_index.append({"data": data, "embedding": np.array(embedding)})
            success_count += 1
            
    with open(INDEX_FILE, 'wb') as f:
        pickle.dump(final_index, f)

    print(f"\nâœ¨ ìƒ‰ì¸ ìƒì„± ì™„ë£Œ! (ì´ {success_count}ê°œ ì €ì¥ë¨)")
    print(f"ê²°ê³¼ íŒŒì¼: {INDEX_FILE}")
    print("ì´ì œ ìŠ¤ë§ˆíŠ¸í•œ ê²€ìƒ‰ì´ ê°€ëŠ¥í•´ì¡ŒìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    # numpy ì„¤ì¹˜ í•„ìš” (ì—†ìœ¼ë©´ pip install numpy)
    try:
        import numpy
    except ImportError:
        os.system("pip install numpy")
        import numpy
        
    create_index()
